{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99797f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camp/anaconda3/envs/diffusion/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "from scipy.ndimage import label\n",
    "import warnings\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "from helpers import *\n",
    "from gaussian_diffusion import GaussianDiffusionModel, get_beta_schedule\n",
    "from unet import UNetModel\n",
    "import data_loader\n",
    "from anomaly_detection import *\n",
    "import skimage.exposure\n",
    "\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import lpips\n",
    "from torch.cuda.amp import autocast\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead71c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, low, high):\n",
    "    \"\"\"\n",
    "    Normalize the input image to the range [low, high].\n",
    "\n",
    "    :param image: Input image as a NumPy array.\n",
    "    :param low: The lower bound of the target range.\n",
    "    :param high: The upper bound of the target range.\n",
    "\n",
    "    :return: The normalized image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Find the minimum and maximum pixel values in the image\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "\n",
    "    # Normalize the image to the range [low, high]\n",
    "    normalized_image = (image - min_val) / (max_val - min_val) * (high - low) + low\n",
    "\n",
    "    # Convert the image to the appropriate data type (uint8 for an image)\n",
    "    normalized_image = normalized_image\n",
    "\n",
    "    return normalized_image\n",
    "\n",
    "def create_gaussian_blur_difference_map(x_0, x_pred, kernel_size=3, threshold=5.0):\n",
    "    \"\"\"\n",
    "    Create a difference map between the input image and the predicted input image with Gaussian blur.\n",
    "\n",
    "    :param x_0: input image\n",
    "    :param x_pred: predicted input image\n",
    "    :param kernel_size: kernel size for Gaussian blur\n",
    "    :param threshold: threshold for anomaly\n",
    "    :return: difference map\n",
    "    \"\"\"\n",
    "\n",
    "    x_0_array = x_0.cpu().squeeze().numpy()\n",
    "    x_0_blurred = cv2.GaussianBlur(x_0_array, (kernel_size, kernel_size), 0)\n",
    "    x_pred_array = x_pred.cpu().detach().numpy().squeeze()\n",
    "    x_pred_blurred = cv2.GaussianBlur(x_pred_array, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    diff = abs(x_0_blurred - x_pred_blurred)\n",
    "    diff[diff < threshold] = 0\n",
    "\n",
    "    diff_final = remove_small_spots(diff)\n",
    "    return diff_final\n",
    "\n",
    "\n",
    "def remove_small_spots(map, threshold=30):\n",
    "    \"\"\"\n",
    "    Remove too small spots from the difference map.\n",
    "\n",
    "    :param map: difference map\n",
    "    :param threshold: threshold for the size of the spots\n",
    "    :return: difference map with removed small spots\n",
    "    \"\"\"\n",
    "\n",
    "    binary_map = map > 0\n",
    "    labeled_map, num_features = label(binary_map)\n",
    "    component_sizes = np.bincount(labeled_map.ravel())\n",
    "    large_components_masked = component_sizes[labeled_map] >= threshold\n",
    "    return large_components_masked * map\n",
    "\n",
    "def get_dice_score(diff_truth, diff_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Dice score between the ground truth and predicted anomaly.\n",
    "\n",
    "    :param diff_truth: ground truth anomaly\n",
    "    :param diff_pred: predicted anomaly\n",
    "    :return: Dice score\n",
    "    \"\"\"\n",
    "\n",
    "    if diff_truth.sum() == 0 and diff_pred.sum() == 0:\n",
    "        return 1.0\n",
    "    dice_score = 2 * (diff_truth & diff_pred).sum() / (diff_truth.sum() + diff_pred.sum())\n",
    "    return round(dice_score, 4)\n",
    "\n",
    "def get_precision_score(diff_truth, diff_pred):\n",
    "    \"\"\"\n",
    "    Calculate the precision score between the ground truth and predicted anomaly.\n",
    "\n",
    "    :param diff_truth: ground truth anomaly\n",
    "    :param diff_pred: predicted anomaly\n",
    "    :return: precision score\n",
    "    \"\"\"\n",
    "\n",
    "    if diff_truth.sum() == 0 and diff_pred.sum() == 0:\n",
    "        return 1.0\n",
    "    true_positives = np.sum(diff_truth & diff_pred)\n",
    "    false_positives = np.sum(diff_pred) - true_positives\n",
    "    if true_positives + false_positives != 0:\n",
    "        precision_score = true_positives / (true_positives + false_positives)\n",
    "    else:\n",
    "        precision_score = 0.0\n",
    "    return round(precision_score, 4)\n",
    "\n",
    "def get_recall_score(diff_truth, diff_pred):\n",
    "    \"\"\"\n",
    "    Calculate the recall score between the ground truth and predicted anomaly.\n",
    "\n",
    "    :param diff_truth: ground truth anomaly\n",
    "    :param diff_pred: predicted anomaly\n",
    "    :return: recall score\n",
    "    \"\"\"\n",
    "\n",
    "    if diff_truth.sum() == 0 and diff_pred.sum() == 0:\n",
    "        return 1.0\n",
    "    true_positives = np.sum(diff_truth & diff_pred)\n",
    "    false_negatives = np.sum(diff_truth) - true_positives\n",
    "    if true_positives + false_negatives != 0:\n",
    "        recall_score = true_positives / (true_positives + false_negatives)\n",
    "    else:\n",
    "        recall_score = 0.0\n",
    "    return round(recall_score, 4)\n",
    "\n",
    "def enlarge_bounding_box(bbox, scale=1.1):\n",
    "    \"\"\"\n",
    "    Enlarge a bounding box by a given scale factor.\n",
    "    \n",
    "    :param bbox: [x_min, y_min, x_max, y_max]\n",
    "    :param scale: Scale factor (default is 1.1 for 10% increase)\n",
    "    :return: Enlarged bounding box [x_min_new, y_min_new, x_max_new, y_max_new]\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    # Compute width and height\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "\n",
    "    # Compute expansion amount (10% increase)\n",
    "    width_increase = (scale - 1) * width / 2\n",
    "    height_increase = (scale - 1) * height / 2\n",
    "\n",
    "    # Apply changes\n",
    "    x_min_new = x_min - width_increase\n",
    "    y_min_new = y_min - height_increase\n",
    "    x_max_new = x_max + width_increase\n",
    "    y_max_new = y_max + height_increase\n",
    "\n",
    "    return [int(x_min_new), int(y_min_new), int(x_max_new), int(y_max_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d41886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = '../output/Ultrasound/model/args_us_27/best_model.pt'\n",
    "# pretrained_path = '../output/BraTS/model/args_brats_12/best_model.pt'\n",
    "# pretrained_path = '../output/LiTS/model/args_lits_14/best_model.pt'\n",
    "betas = get_beta_schedule(\"cosine\", 1000)\n",
    "\n",
    "diffusion = GaussianDiffusionModel(\n",
    "            128, betas, img_channels=1, loss_type=\"vlb\",\n",
    "            loss_weight=\"none\", noise_fn=\"gaussian\", noise_params=None, diffusion_mode=\"inference\"\n",
    "            )\n",
    "\n",
    "model = UNetModel(128, in_channels=1, model_channels=128,\n",
    "                num_res_blocks=2, attention_resolutions=\"32,16,8\",\n",
    "                dropout=0.0, channel_mult=\"\", num_heads=2,\n",
    "                num_head_channels=64,).to('cuda')\n",
    "\n",
    "checkpoint = torch.load(pretrained_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d785970f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_path = \"/home/camp/Projects/Yuan/Data/Ultrasound_synomaly/unhealthy_selected\"\n",
    "folders = os.listdir(root_path)\n",
    "folders.sort()\n",
    "dice_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "noise_steps = [250]\n",
    "kernel = 15\n",
    "threshold = 0.3\n",
    "\n",
    "for f in folders:\n",
    "    img_files = os.listdir(os.path.join(root_path,f,\"img\"))\n",
    "    mask_files = os.listdir(os.path.join(root_path,f,\"plaque\"))\n",
    "    img_files.sort()\n",
    "    mask_files.sort()\n",
    "    try:\n",
    "        b_boxes = np.load(os.path.join(root_path,f,\"b_boxes.npy\"))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    \n",
    "    for i, (img_filename, mask_filename, bbox) in enumerate(zip(img_files, mask_files, b_boxes)):\n",
    "        if i <5:\n",
    "            continue\n",
    "        img = cv2.imread(os.path.join(root_path,f,\"img\",img_filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        mask = cv2.imread(os.path.join(root_path,f,\"plaque\",mask_filename))\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        bbox = enlarge_bounding_box(bbox, scale = 1.1)\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "        # Crop the image\n",
    "        img = img[y_min:y_max, x_min:x_max]\n",
    "        mask = mask[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = normalize_image(img, -1, 1)\n",
    "        \n",
    "        mask = cv2.resize(mask, (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        x_0 = torch.from_numpy(img).float().view(1,1,128,128).to('cuda')\n",
    "        device = 'cuda'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_0_cache = x_0\n",
    "\n",
    "            inference_images = []\n",
    "            inference_images.append(x_0)\n",
    "\n",
    "            difference_map_cache = np.ones_like(x_0.cpu().squeeze().numpy())\n",
    "            iter_num = 0\n",
    "            difference = 255*255\n",
    "\n",
    "            while difference > 0.01:\n",
    "                t = torch.tensor(noise_steps, device=x_0_cache.device).repeat(x_0_cache.shape[0])\n",
    "                noise = diffusion.noise_fn(x_0_cache, None)\n",
    "                x_t = diffusion.q_sample(x_0_cache, t, noise)\n",
    "                x_pred = diffusion.p_sample(model, x_t, t)\n",
    "\n",
    "                # x_0_cache=x_pred\n",
    "\n",
    "\n",
    "\n",
    "                difference_map = create_gaussian_blur_difference_map(x_0, x_pred,\n",
    "                                                                     kernel_size=3,\n",
    "                                                                     threshold=0.1)\n",
    "                difference_map = difference_map.astype(bool).astype(int)\n",
    "\n",
    "                difference_map_t = torch.from_numpy(difference_map)\n",
    "                difference_map_t = difference_map_t.view(1,1,128,128).to(device)\n",
    "                x_0_cache = x_pred*difference_map_t+x_0*(1-difference_map_t)\n",
    "\n",
    "                inference_images.extend([x_t, x_0_cache])\n",
    "\n",
    "\n",
    "                nominator = np.abs(np.sum(difference_map_cache.astype(bool).astype(int))-np.sum(difference_map.astype(bool).astype(int)))\n",
    "                denominator = np.max([np.sum(difference_map_cache.astype(bool).astype(int)),500])\n",
    "                difference = nominator/denominator\n",
    "                difference_map_cache = difference_map\n",
    "                iter_num += 1\n",
    "                if iter_num>=5:\n",
    "                    break\n",
    "\n",
    "        anomaly_map = create_gaussian_blur_difference_map(x_0,x_pred,kernel_size=kernel, threshold=threshold)\n",
    "        \n",
    "        predicted_anomaly = anomaly_map.astype(bool)\n",
    "        groundtruth_anomaly = mask.astype(bool)\n",
    "        \n",
    "        dice = get_dice_score(groundtruth_anomaly, predicted_anomaly)\n",
    "        precision = get_precision_score(groundtruth_anomaly, predicted_anomaly)\n",
    "        recall = get_recall_score(groundtruth_anomaly, predicted_anomaly)\n",
    "        \n",
    "        dice_list.append(dice)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80951b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6765760948905108\n",
      "0.8702777372262773\n",
      "0.5971979927007299\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dice_list).mean())\n",
    "print(np.array(precision_list).mean())\n",
    "print(np.array(recall_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd91adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754642335766423\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dice_list).mean())\n",
    "print(np.array(precision_list).mean())\n",
    "print(np.array(recall_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45377be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6765760948905108 0.18851480027108342\n",
      "0.8702777372262773\n",
      "0.5971979927007299\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dice_list).mean(), np.array(dice_list).std())\n",
    "print(np.array(precision_list).mean())\n",
    "print(np.array(recall_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a331b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
